<!DOCTYPE html>
<html>
<head>
	<title>DATA PREPROCESSING : FEATURE SELECTION</title>
	<style>
		.post-container {
    margin: 20px 20px 0 0;  
    border: 5px solid #333;
    overflow: auto
}
.post-thumb {
    float: left
}
.post-thumb img {
    display: block;
    width: 200px;
    height: auto;
}
.post-content {
    margin-left: 210px
}
.post-title {
    font-weight: bold;
    font-size: 200%;
    padding: 9px;
    background: #ccc
}

.tabs {
  margin-top: 20px;
}

.tabs ul {
  list-style: none;
  margin: 0;
  padding: 0;
  display: flex;
  justify-content: space-between;
}

.tabs li {
  flex: 1;
  text-align: center;
}

.tabs li a {
  display: block;
  padding: 10px;
  background-color: #f2f2f2;
  color: #333;
  text-decoration: none;
  border: 1px solid #ccc;
  border-bottom: none;
}

.tabs li.active a {
  background-color: #fff;
  border-color: #ccc;
}

.tab-content {
  display: none;
}

.tab-content.active {
  display: block;
}

.tab-content table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 1px;
}

.tab-content table th,
.tab-content table td {
  padding: 5px;
  text-align: center;
  border: 1px solid #ccc;
}
	</style>
</head>
<body>

	

  <div class="post-container">
    <h3 class="post-title">DATA PREPROCESSING : FEATURE SELECTION</h3>
    <div class="post-thumb"><img src="/static/datapreprocess.jpeg" alt="DATA PREPROCESSING"/></div>
    <div class="post-content">
        <p>Steps to make data usable by the ML modelâ€“e.g., dropping or imputing missing values, transforming 
            (standardizing or normalizing data), as well as feature engineering, i.e. deciding how to construct 
            features from available information for use in the model, and which of the constructed features to use for prediction. 
            Again, there are myriad ways for biases to enter through feature engineering decisions such as building features from data 
            that is likely to be of higher quality for some groups, using data transformations with differential error rates across groups, 
            imputing missing data in ways that have differential accuracy across groups, selecting features which are differentially informative 
            across demographic populations, or choosing normatively objectionable features to use for a prediction task, such as whether or not the family 
            members of a defendant have criminal records to determine whether they are recommended for release or to be jailed.</p>
    </div>
  </div>
    <div class="tabs">
      <ul>
        <li><a href="#problemidentification">Problem Identification</a></li>
        <li><a href="#measurement">Measurement</a></li>
        <li><a href="#mitigation">Mitigation</a></li>
      </ul>
      <div class="tab-content" id="problemidentification">
        <table>
          <thead>
            <tr>
              <th>Paper Title</th>
              <th>Authors</th>
              <th>Description</th>
              <th>Tags/Comments</th>
              <th>Conference Venue</th>
              <th>Year</th>
              <th>Paper link</th>
              <th>Additional resources</th>
            </tr>
          </thead>
          <tbody>
            <!-- <tr>
                <td>A Bio-Inspired Framework for Machine Bias Interpretation</td>
                <td>Jake Robertson, Catherine Stinson, Ting Hu</td>
                <td>N/A</td>
                <td>Data Preprocessing, Feature Selection, Problem Identification</td>
                <td>AIES</td>
                <td>2022</td>
                <td><a href="https://dl.acm.org/doi/10.1145/3514094.3534126">A Bio-Inspired Framework for Machine Bias Interpretation</a></td>
                <td>None</td>
              </tr>
              <tr>
                <td>Feature-Wise Bias Amplification</td>
                <td>Klas Leino, Emily Black, Matt Fredrikson, Shayak Sen, Anupam Datta</td>
                <td>N/A</td>
                <td>Data Preprocessing, Feature Selection, Problem Identification</td>
                <td>ICLR</td>
                <td>2019</td>
                <td><a href="https://openreview.net/forum?id=S1ecm2C9K7">Feature-Wise Bias Amplification</a></td>
                <td>None</td>
              </tr> -->
              {% for row in sub_table1 %}
              <tr>
                {% for cell in row %}
                <td>{{ cell }}</td>
                {% endfor %}
              </tr>
              {% endfor %}
              
          </tbody>
        </table>
      </div>
      <div class="tab-content" id="measurement">
        <table>
          <thead>
            <tr>
              <th>Paper Title</th>
              <th>Authors</th>
              <th>Description</th>
              <th>Tags/Comments</th>
              <th>Conference Venue</th>
              <th>Year</th>
              <th>Paper link</th>
              <th>Additional resources</th>
            </tr>
          </thead>
          <tbody>
            <!-- <tr>
                <td>Automating Procedurally Fair Feature Selection in Machine Learning</td>
                <td>Clara Belitz, Lan Jiang, Nigel Bosch</td>
                <td>N/A</td>
                <td>Data Preprocessing, Feature Selection, Measurement</td>
                <td>AIES</td>
                <td>2021</td>
                <td><a href="https://dl.acm.org/doi/10.1145/3461702.3462585">Automating Procedurally Fair Feature Selection in Machine Learning</a></td>
                <td>None</td>
              </tr>
              <tr>
                <td>Assessing Social and Intersectional Biases in Contextualized Word Representations</td>
                <td>Yi Chern Tan, L. Elisa Celis</td>
                <td>N/A</td>
                <td>Data Preprocessing, Feature Selection, Measurement</td>
                <td>NeurIPS</td>
                <td>2019</td>
                <td><a href="https://proceedings.neurips.cc//paper/2019/hash/201d546992726352471cfea6b0df0a48-Abstract.html">Assessing Social and Intersectional Biases in Contextualized Word Representations</a></td>
                <td>None</td>
              </tr> -->
              {% for row in sub_table2 %}
              <tr>
                {% for cell in row %}
                <td>{{ cell }}</td>
                {% endfor %}
              </tr>
              {% endfor %}
          </tbody>
        </table>
      </div>
      <div class="tab-content" id="mitigation">
        <table>
          <thead>
            <tr>
              <th>Paper Title</th>
              <th>Authors</th>
              <th>Description</th>
              <th>Tags/Comments</th>
              <th>Conference Venue</th>
              <th>Year</th>
              <th>Paper link</th>
              <th>Additional resources</th>
            </tr>
          </thead>
          <tbody>
            <!-- <tr>
                <td>Hunting for Discriminatory Proxies in Linear Regression Models</td>
                <td>Samuel Yeom, Anupam Datta, Matt Fredrikson</td>
                <td>N/A</td>
                <td>Data Preprocessing, Feature Selection, Mitigation</td>
                <td>NeurIPS</td>
                <td>2018</td>
                <td><a href="https://proceedings.neurips.cc//paper/2018/hash/6cd9313ed34ef58bad3fdd504355e72c-Abstract.html">Hunting for Discriminatory Proxies in Linear Regression Models</a></td>
                <td>None</td>
              </tr>
              <tr>
                <td>Fairness for AUC via Feature Augmentation</td>
                <td>Hortense Fong, Vineet Kumar, Anay Mehrotra, Nisheeth K. Vishnoi</td>
                <td>N/A</td>
                <td>Data Preprocessing, Feature Selection, Mitigation</td>
                <td>FAccT</td>
                <td>2022</td>
                <td><a href="https://dl.acm.org/doi/10.1145/3531146.3533126">Fairness for AUC via Feature Augmentation</a></td>
                <td>None</td>
              </tr> -->
              {% for row in sub_table3 %}
              <tr>
                {% for cell in row %}
                <td>{{ cell }}</td>
                {% endfor %}
              </tr>
              {% endfor %}
          </tbody>
        </table>
    </div>
  </div>
    
    <!-- JavaScript for the tabs -->
    <script>
      const tabLinks = document.querySelectorAll('.tabs li a');
      const tabContents = document.querySelectorAll('.tab-content');

      tabLinks.forEach((link) => {
        link.addEventListener('click', (e) => {
          e.preventDefault();

          const targetId = e.target.getAttribute('href').substr(1);

          tabLinks.forEach((link) => {
            link.parentNode.classList.remove('active');
          });

          tabContents.forEach((content) => {
            content.classList.remove('active');
          });

          e.target.parentNode.classList.add('active');
          document.getElementById(targetId).classList.add('active');
        });
      });
    </script>
  </body>
</html>