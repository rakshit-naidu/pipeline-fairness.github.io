<!DOCTYPE html>
<html>
<head>
	<title>DATA COLLECTION : SAMPLING BIAS</title>
	<style>
		.post-container {
    margin: 20px 20px 0 0;  
    border: 5px solid #333;
    overflow: auto
}
.post-thumb {
    float: left
}
.post-thumb img {
    display: block;
    width: 200px;
    height: auto;
}
.post-content {
    margin-left: 210px
}
.post-title {
    font-weight: bold;
    font-size: 200%;
    padding: 9px;
    background: #ccc
}

.tabs {
  margin-top: 20px;
}

.tabs ul {
  list-style: none;
  margin: 0;
  padding: 0;
  display: flex;
  justify-content: space-between;
}

.tabs li {
  flex: 1;
  text-align: center;
}

.tabs li a {
  display: block;
  padding: 10px;
  background-color: #f2f2f2;
  color: #333;
  text-decoration: none;
  border: 1px solid #ccc;
  border-bottom: none;
}

.tabs li.active a {
  background-color: #fff;
  border-color: #ccc;
}

.tab-content {
  display: none;
}

.tab-content.active {
  display: block;
}

.tab-content table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 1px;
}

.tab-content table th,
.tab-content table td {
  padding: 5px;
  text-align: center;
  border: 1px solid #ccc;
}
	</style>
</head>
<body>

	

  <div class="post-container">
    <h3 class="post-title">DATA COLLECTION : SAMPLING BIAS</h3>
    <div class="post-thumb"><img src="/static/floppy.png" alt="DATA COLLECTION"/></div>
    <div class="post-content">
        <p>Collecting or compiling data to train the model. This involves making choices—or implicitly
          accepting previously made choices—about how to sample, label, link, and omit data. Some questions include—
          What population will we sample to build our model? How will we collect this data? How will we measure our
          prediction task? How will we define a positive label based on the prediction task? Who will label our data? How
          will we link across data sources?</p>
    </div>
  </div>
    <div class="tabs">
      <ul>
        <li><a href="#casestudy">Case Study</a></li>
        <li><a href="#problemidentification">Problem Identification</a></li>
        <li><a href="#measurement">Measurement</a></li>
        <li><a href="#mitigation">Mitigation</a></li>
      </ul>
      <div class="tab-content" id="casestudy">
        <table>
          <thead>
            <tr>
              <th>Paper Title</th>
              <th>Authors</th>
              <th>Description</th>
              <th>Tags/Comments</th>
              <th>Conference Venue</th>
              <th>Year</th>
              <th>Paper link</th>
              <th>Additional resources</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification</td>
              <td>Joy Buolamwini, Timnit Gebru</td>
              <td>N/A</td>
              <td>Data Collection, Data Sampling, Case Study</td>
              <td>FAccT</td>
              <td>2018</td>
              <td><a href="https://proceedings.mlr.press/v81/buolamwini18a.html">Gender Shades</a></td>
              <td>None</td>
            </tr>
            <tr>
              <td>Censorship of Online Encyclopedias: Implications for NLP Models</td>
              <td>Eddie Yang, Margaret E. Roberts</td>
              <td>N/A</td>
              <td>Data Collection, Data Sampling, Case study</td>
              <td>FAccT</td>
              <td>2021</td>
              <td><a href="https://dl.acm.org/doi/10.1145/3442188.3445916">Censorship of Online Encyclopedias</a></td>
              <td>None</td>
            </tr>
            <tr>
              <td>Towards Intersectional Feminist and Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection</td>
              <td>Harini Suresh, Rajiv Movva, Amelia Lee Dogan, Rahul Bhargava, Isadora Cruxen, Angeles Martinez Cuba, Guilia Taurino, Wonyoung So, Catherine D'Ignazio</td>
              <td>N/A</td>
              <td>Data Collection, Data Sampling, Case study</td>
              <td>FAccT</td>
              <td>2022</td>
              <td><a href="https://dl.acm.org/doi/10.1145/3531146.3533132">Towards Intersectional Feminist and Participatory ML</a></td>
              <td>None</td>
            </tr>
            <tr>
              <td>Female, white, 27? Bias Evaluation on Data and Algorithms for Affect Recognition in Faces</td>
              <td>Jaspar Pahl, Ines Rieger, Anna Möller, Thomas Wittenberg, Ute Schmid</td>
              <td>N/A</td>
              <td>Data Collection, Data Sampling, Case study</td>
              <td>FAccT</td>
              <td>2022</td>
              <td><a href="https://dl.acm.org/doi/10.1145/3531146.3533159">Female, white, 27?</a></td>
              <td>None</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="tab-content" id="problemidentification">
        <table>
          <thead>
            <tr>
              <th>Paper Title</th>
              <th>Authors</th>
              <th>Description</th>
              <th>Tags/Comments</th>
              <th>Conference Venue</th>
              <th>Year</th>
              <th>Paper link</th>
              <th>Additional resources</th>
            </tr>
          </thead>
          <tbody>
          </tbody>
        </table>
      </div>
      <div class="tab-content" id="measurement">
        <table>
          <thead>
            <tr>
              <th>Paper Title</th>
              <th>Authors</th>
              <th>Description</th>
              <th>Tags/Comments</th>
              <th>Conference Venue</th>
              <th>Year</th>
              <th>Paper link</th>
              <th>Additional resources</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Modeling Risk and Achieving Algorithmic Fairness Using Potential Outcomes</td>
              <td>Alan Mishler</td>
              <td>N/A</td>
              <td>Data Collection, Data Sampling, Measurement</td>
              <td>AIES</td>
              <td>2019</td>
              <td><a href="https://dl.acm.org/doi/10.1145/3306618.3314323">Modeling Risk and Achieving Algorithmic Fairness Using Potential Outcomes</a></td>
              <td>None</td>
            </tr>
          </tbody>
        </table>
      </div>
      <div class="tab-content" id="mitigation">
        <table>
          <thead>
            <tr>
              <th>Paper Title</th>
              <th>Authors</th>
              <th>Description</th>
              <th>Tags/Comments</th>
              <th>Conference Venue</th>
              <th>Year</th>
              <th>Paper link</th>
              <th>Additional resources</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Data Augmentation for Discrimination Prevention and Bias Disambiguation</td>
              <td>Shubham Sharma, Yunfeng Zhang, Jesús M. Ríos Aliaga, Djallel Bouneffouf, Vinod Muthusamy, Kush R. Varshney</td>
              <td>N/A</td>
              <td>Data Collection, Data Sampling, Mitigation</td>
              <td>AIES</td>
              <td>2020</td>
              <td><a href="https://dl.acm.org/doi/10.1145/3375627.3375865">Data Augmentation for Discrimination Prevention and Bias Disambiguation</a></td>
              <td>None</td>
            </tr>
            <tr>
              <td>DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks</td>
              <td>Boris van Breugel, Trent Kyono, Jeroen Berrevoets, Mihaela van der Schaar</td>
              <td>N/A</td>
              <td>Data Collection, Data Sampling, Mitigation</td>
              <td>NeurIPS</td>
              <td>2021</td>
              <td><a href="https://proceedings.neurips.cc//paper/2021/hash/ba9fab001f67381e56e410575874d967-Abstract.html">DECAF</a></td>
              <td>None</td>
            </tr>
            <tr>
              <td>Detecting discriminatory risk through data annotation based on Bayesian inferences</td>
              <td>Elena Beretta, Antonio Vetrò, Bruno Lepri, Juan Carlos De Martin</td>
              <td>N/A</td>
              <td>Data Collection, Data Sampling, Mitigation</td>
              <td>FAccT</td>
              <td>2021</td>
              <td><a href="https://dl.acm.org/doi/10.1145/3442188.3445940">Detecting discriminatory risk through data annotation based on Bayesian inferences</a></td>
              <td>None</td>
            </tr>
          </tbody>
        </table>
    </div>
  </div>
    
    <!-- JavaScript for the tabs -->
    <script>
      const tabLinks = document.querySelectorAll('.tabs li a');
      const tabContents = document.querySelectorAll('.tab-content');

      tabLinks.forEach((link) => {
        link.addEventListener('click', (e) => {
          e.preventDefault();

          const targetId = e.target.getAttribute('href').substr(1);

          tabLinks.forEach((link) => {
            link.parentNode.classList.remove('active');
          });

          tabContents.forEach((content) => {
            content.classList.remove('active');
          });

          e.target.parentNode.classList.add('active');
          document.getElementById(targetId).classList.add('active');
        });
      });
    </script>
  </body>
</html>