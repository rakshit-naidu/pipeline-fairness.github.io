,Paper Title,Authors,Description,Tags/Comments,Conference Venue,Year,Paper link,Additional resources
0,The Fallacy of AI Functionality,"Inioluwa Deborah Raji, I. Elizabeth Kumar, Aaron Horowitz, Andrew D. Selbst",,"Viability Assessments-General, Problem Identification",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533158,
1,"When not to design, build, or deploy","Solon Barocas, Biega, Asia J., Biega, Benjamin Fish, Jundefineddrzej Niklas, Luke Stark",,"Viability Assessments-General, Problem Identification",FAccT,2020,https://dl.acm.org/doi/abs/10.1145/3351095.3375691,
2,Against Predictive Optimization: On the Legitimacy of Decision-Making Algorithms that Optimize Predictive Accuracy,"Angelina Wang, Sayash Kapoor, Solon Barocas, Arvind Narayanan",,"Viability Assessments-General, Measurement",SSRN,2022,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4238015,
3,A validity perspective on evaluating the justified use of data-driven decision-making algorithms,"Ama Coston, Anna Kawakami, Haiyi Zhu, Ken Holstein, Hoda Heidari",,"Viability Assessments-General, Measurement",SATML,2023,https://arxiv.org/abs/2206.14983,
4,Algorithmic fairness and vertical equity: Income fairness with irs tax audit models,"Emily Black, Hadi Elzayn, Alexra Chouldechova, Jacob Goldin, Daniel Ho",,"Problem Formulation-Prediction Target, Problem Identification (Case Study)",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533204,
5,Dissecting racial bias in an algorithm used to manage the health of populations,"Ziad Obermeyer, Brian Powers, Christine Vogeli, Sendhil Mullainathan",,"Problem Formulation-Prediction Target, Problem Identification (Case Study)",Science,2019,https://www.science.org/doi/abs/10.1126/science.aax2342,
6,Data augmentation for fairness-aware machine learning: Preventing algorithmic bias in law enforcement systems,"Ioannis Pastaltzidis, Nikolaos Dimitriou, Katherine Quezada-Tavarez, Stergios Aidinlis, Thomas Marquenie, Agata Gurzawska, Dimitrios Tzovaras",,"Problem Formulation-Prediction Target, Problem Identification (Case Study)",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3534644,
7,"The distributive effects of risk prediction in environmental compliance: Algorithmic design, environmental justice, and public policy","Elinor Benami, Reid Whitaker, Vincent La, Hongjin Lin, Bron R Anderson, Daniel E Ho",,"Problem Formulation-Prediction Target, Mitigation",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445873,
8,Beyond distributive fairness in algorithmic decision making: Feature selection for procedurally fair learning,"Nina Grgić-Hlača, Muhammad Bilal Zafar, Krishna P Gummadi, Adrian Weller",,"Problem Formulation-Predictive Attributes, Problem Identification",AAAI,2018,https://ojs.aaai.org/index.php/AAAI/article/view/11296,
9,"Modeling assumptions clash with the real world: Transparency, equity, and community challenges for student assignment algorithms.","Samantha Robertson, Tonya Nguyen, Niloufar Salehi.",,"Problem Formulation-General, Problem Identification (Case study)",CHI,2021,https://dl.acm.org/doi/10.1145/3411764.3445748,
10,Algorithmic management reimagined for workers and by workers: Centering worker well-being in gig work,"Angie Zhang, Alexer Boltz, Chun Wei Wang, Min Kyung Lee",,"Problem Formulation-General, Problem Identification (Case study)",CHI,2022,https://dl.acm.org/doi/10.1145/3491102.3501866,
11,Re-imagining systems in the realm of immigration in higher education through participatory design.,Maria Conchita A. Navarro  Orit Shaer,,"Problem Formulation-General, Problem Identification (Case study)",CSCW,2022,https://dl.acm.org/doi/10.1145/3500868.3559457,
12,"""I feel like I need to split myself in half"": Using Role Theory to Design for Parents as Caregiving Teams in the Children's Hospital","Sarah Nikkhah, Akash Uday Rode, Priyanjali Mittal, Neha K. Kulkarni, Salonee Nadkarni, Emily L. Mueller,  Andrew D. Miller",,"Problem Formulation-General, Problem Identification (Case study)",CSCW,2022,https://dl.acm.org/doi/10.1145/3500868.3559466,
13,Problem formulation and fairness,"Samir Passi, Solon Barocas",,"Problem Formulation-General, Problem Identification",FAccT,2019,https://dl.acm.org/doi/10.1145/3287560.3287567,
14,A case study of algorithm-assisted decision making in child maltreatment hotline screening decisions,"Alexra Chouldechova, Diana Benavides-Prado, Oleksr Fialko,  Rhema Vaithianathan",,"Problem Formulation-General, Problem Identification (Case study)",FAccT,2018,https://proceedings.mlr.press/v81/chouldechova18a.html,
15,Measurement and Fairness,Abigail Z. Jacobs  Hanna Wallach,,"Problem Formulation-General, Problem Identification",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445901,
16,Soliciting stakeholders’ fairness notions in child maltreatment predictive systems,"Hao-Fei Cheng, Logan Stapleton, Ruiqi Wang, Paige Bullock, Alexra Chouldechova, Zhiwei Steven Wu,  Haiyi Zhu",,"Problem Formulation-General, Problem Identification",CHI,2021,https://dl.acm.org/doi/10.1145/3411764.3445308,
17,Multi-category fairness in sponsored search auctions,"Christina Ilvento, Meena Jagadeesan,  Shuchi Chawla",,"Problem Formulation-General, Problem Identification (Case study)",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372848,
18,To Predict and Serve?,"Kristian Lum, William Isaac",,"Problem Formulation-General, Problem Identification",Significance,2016,https://academic.oup.com/jrssig/article/13/5/14/7029190,
19,Gender shades: Intersectional accuracy disparities in commercial gender classification,"Joy Buolamwini, Timnit Gebru",,"Data Collection-Sampling, Problem Identification (Case Study)",FAccT,2018,https://proceedings.mlr.press/v81/buolamwini18a.html,
20,Censorship of online encyclopedias: Implications for nlp models ,"Eddie Yang, Margaret E. Roberts",,"Data Collection-Sampling, Problem Identification (Case Study)",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445916,
21,Towards intersectional feminist and participatory ml: A case study in supporting feminicide counterdata collection,"Harini Suresh, Rajiv Movva, Amelia Lee Dogan, Rahul Bhargava, Isadora Cruxen, Angeles Martinez Cuba, Guilia Taurino, Wonyoung So, Catherine D’Ignazio",,"Data Collection-Sampling, Problem Identification (Case Study)",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533132,
22,"Female, white, 27? Bias evaluation on data and algorithms for affect recognition in faces","Jaspar Pahl, Ines Rieger, Anna Möller, Thomas Wittenberg, Ute Schmid",,"Data Collection-Sampling, Problem Identification (Case Study)",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533159,
23,Adaptive sampling strategies to construct equitable training datasets,"William Cai, Ro Encarnacion, Bobbie Chern, Sam Corbett-Davies, Mira Bogen, Stevie Bergman, Sharad Goel",,"Data Collection-Sampling, Problem Identification",FAccT,2022,https://arxiv.org/abs/2202.01327,
24,Modeling risk and achieving algorithmic fairness using potential outcomes,Alan Mishler,,"Data Collection-Sampling, Measurement",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314323,
25,Identifying bias in data using two-distribution hypothesis tests,"William Yik, Limnanthes Serafini, Timothy Lindsey, George D Montañez",,"Data Collection-Sampling, Measurement",AIES,2022,https://dl.acm.org/doi/abs/10.1145/3514094.3534169,
26,Data augmentation for discrimination prevention and bias disambiguation,"Shubham Sharma, Yunfeng Zhang, Jesús M Ríos Aliaga, Djallel Bouneffouf, Vinod Muthusamy,  Kush R Varshney",,"Data Collection-Sampling, Mitigation",AIES,2020,https://dl.acm.org/doi/10.1145/3375627.3375865,
27,DECAF: Generating Fair Synthetic Data Using Causally-Aware Generative Networks,"Boris van Breugel, Trent Kyono, Jeroen Berrevoets,  Mihaela van der Schaar",,"Data Collection-Sampling, Mitigation",NeurIPS,2019,https://openreview.net/forum?id=XN1M27T6uux,
28,Detecting discriminatory risk through data annotation based on bayesian inferences,"Elena Beretta, Antonio Vetrò, Bruno Lepri,  Juan Carlos De Martin",,"Data Collection-Sampling, Mitigation",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445940,
29,Conditional contrastive learning with kernel,"Yao-Hung Hubert Tsai, Tianqin Li, Martin Q. Ma, Han Zhao, Kun Zhang, Louis-Philippe Morency,  Ruslan Salakhutdinov.",,"Data Collection-Sampling, Mitigation (Traditional)",ICLR,2022,https://openreview.net/forum?id=AAJLBoGt0XM,
30,Adaptive Sampling for Minimax Fair Classification,"Shubhanshu Shekhar, Greg Fields, Mohammad Ghavamzadeh,  Tara Javidi",,"Data Collection-Sampling, Mitigation (Traditional)",NeurIPS,2021,https://openreview.net/forum?id=ZDMqRGSksHs,
31,Fairbatch: Batch selection for model fairness,"Yuji Roh, Kangwook Lee, Steven Euijong Whang,  Changho Suh",,"Data Collection-Sampling, Mitigation (Traditional)",ICLR,2021,https://openreview.net/forum?id=YNnpaAKeCfx,
32,Learning with noisy labels revisited: A study using real-world human annotations,"Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu,  Yang Liu",,"Data Collection-Annotation, Problem Identification (Case Study)",ICLR,2022,https://openreview.net/forum?id=TBWA6PLJZQm,
33,Fair classification with group-dependent label noise,"Jialu Wang, Yang Liu, Caleb Levy",,"Data Collection-Annotation, Problem Identification",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445915,
34,Assessing annotator identity sensitivity via item response theory: A case study in a hate speech corpus,"Pratik S. Sachdeva, Renata Barreto, Claudia von Vacano,  Chris J. Kennedy",,"Data Collection-Annotation, Problem Identification",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533216,
35,It’s about time: A view of crowdsourced data before and during the pandemic,"Evgenia Christoforou, Pinar Barlas, Jahna Otterbacher",,"Data Collection-Annotation, Problem Identification",CHI,2021,https://dl.acm.org/doi/10.1145/3411764.3445317,
36,Can less be more? when increasing-to-balancing label noise rates considered beneficial.,"Yang Liu, Jialu Wang",,"Data Collection-Annotation, Measurement",NeurIPS,2021,https://openreview.net/forum?id=VjKhSULF7Gb,
37,Measuring representational harms in image captioning,"Angelina Wang, Solon Barocas, Kristen Laird, Hanna Wallach",,"Data Collection-Annotation, Measurement",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533099,
38,The Values Encoded in Machine Learning Research ,"Abeba Birhane, Pratyusha Kalluri, Dallas Card, William Agnew, Ravit Dotan,  Michelle Bao",,"Data Collection-Annotation, Measurement",FAccT,2022,https://dl.acm.org/doi/fullHtml/10.1145/3531146.3533083,
39,Towards fairer datasets: Filtering and balancing the distribution of the people subtree in the imagenet hierarchy,"Kaiyu Yang, Klint Qinami, Li Fei-Fei, Jia Deng,  Olga Russakovsky",,"Data Collection-Annotation, Mitigation",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3375709,
40,Fairness in representation for multilingual NLP: Insights from controlled experiments on conditional language modeling,Ada Wan,,"Data Collection-Feature Measurement, Problem Identification (Case Study)",ICLR,2022,https://openreview.net/forum?id=-llS6TiOew,
41,Disparate impact of artificial intelligence bias in ridehailing economy’s price discrimination algorithms.,"Akshat Pey, Aylin Caliskan",,"Data Collection-Feature Measurement, Problem Identification (Case Study)",AIES,2021,https://arxiv.org/abs/2006.04599,
42,Asymmetric shapley values: incorporating causal knowledge into model-agnostic explainability,"Christopher Frye, Colin Rowat, Ilya Feige",,"Data Collection-Feature Measurement, Problem Identification",NeurIPS,2020,https://dl.acm.org/doi/10.5555/3495724.3495828,
43,What are the biases in my word embedding?,"Nathaniel Swinger, Maria De-Arteaga, Neil Thomas Heffernan IV, Mark DM Leiserson,  Adam Tauman Kalai",,"Data Collection-Feature Measurement, Measurement",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314270,
44,Dynamic covid risk assessment accounting for community virus exposure from a spatial-temporal transmission model,"Yuan Chen, Wenbo Fei, Qinxia Wang, Donglin Zeng,  Yuanjia Wang",,"Data Collection-General, Problem Identification (Case Study)",NeurIPS,2021,https://proceedings.neurips.cc/paper/2021/hash/e97a4f04ef1b914f6a1698caa364f693-Abstract.html,
45,Investigating and mitigating biases in crowdsourced data,"Danula Hettiachchi, Mark Serson, Jorge Goncalves, Simo Hosio, Gabriella Kazai, Matthew Lease, Mike Schaekermann,  Emine Yilmaz",,"Data Collection-General, Problem Identification (Case Study)",CSCW,2021,https://dl.acm.org/doi/10.1145/3462204.3481729,
46,"“Everyone wants to do the model work, not the data work”: Data Cascades in High-Stakes AI","Nithya Sambasivan, Shivani Kapania, Hannah Highfill, Diana Akrong, Praveen Paritosh,  Lora M Aroyo",,"Data Collection-General, Problem Identification (Case Study)",CHI,2021,https://dl.acm.org/doi/10.1145/3411764.3445518,
47,Designing an online infrastructure for collecting ai data from people with disabilities,"Joon Sung Park, Danielle Bragg, Ece Kamar,  Meredith Ringel Morris",,"Data Collection-General, Problem Identification",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445870,
48,Residual unfairness in fair machine learning from prejudiced data,"Nathan Kallus, Angela Zhou",,"Data Collection-General, Problem Identification",ICML,2018,https://proceedings.mlr.press/v80/kallus18a.html,
49,Data in new delhi’s predictive policing system,"Vidushi Marda, Shivangi Narayan",,"Data Collection-General, Problem Identification",FAccT,2020,https://dl.acm.org/doi/abs/10.1145/3351095.3372865,
50,Data-centric factors in algorithmic fairness,"Nianyun Li, Naman Goel,  Elliott Ash",,"Data Collection-General, Measurement",AIES,2022,https://dl.acm.org/doi/10.1145/3514094.3534147,
51,Retiring adult: New datasets for fair machine learning,"Frances Ding, Moritz Hardt, John Miller,  Ludwig Schmidt",,"Data Collection-General, Measurement",NeurIPS,2021,https://openreview.net/forum?id=bYi_2708mKK,
52,Assessing fairness in the presence of missing data,"Yiliang Zhang, Qi Long",,"Data Collection-General, Measurement",NeurIPS,2021,https://openreview.net/forum?id=myJO35O7Gg,
53,Understanding the representation and representativeness of age in ai data sets,"Joon Sung Park, Michael S. Bernstein, Robin N. Brewer, Ece Kamar,  Meredith Ringel Morris",,"Data Collection-General, Measurement",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462590,
54,Can I Trust My Fairness Metric? Assessing Fairness with Unlabeled Data and Bayesian Inference,"Disi Ji, Padhraic Smyth,  Mark Steyvers",,"Data Collection-General, Measurement",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/d83de59e10227072a9c034ce10029c39-Abstract.html,
55,Assessing algorithmic fairness with unobserved protected class using data combination,"Nathan Kallus, Xiaojie Mao,  Angela Zhou",,"Data Collection-General, Measurement",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3373154,
56,The effect of differential victim crime reporting on predictive policing systems,"Nil-Jana Akpinar, Maria De-Arteaga,  Alexra Chouldechova",,"Data Collection-General, Measurement",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445877,
57,Man is to computer programmer as woman is to homemaker? debiasing word embeddings,"Tolga Bolukbasi, Kai-Wei Chang, James Y Zou, Venkatesh Saligrama,  Adam T Kalai",,"Data Collection-General, Measurement",NeurIPS,2016,https://dl.acm.org/doi/10.5555/3157382.3157584,
58,Data preprocessing techniques for classification without discrimination,"Faisal Kamiran, Toon Calders",,"Data Collection-General, Measurement",Knowledge and Information Systems,2012,https://link.springer.com/article/10.1007/s10115-011-0463-8,
59,Why is my classifier discriminatory?,"Irene Chen, Fredrik D Johansson,  David Sontag",,"Data Collection-General, Mitigation",NeurIPS,2018,https://dl.acm.org/doi/10.5555/3327144.3327272,
60,Datasheets for Datasets,"Timnit Gebru, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal III Daumé,  Kate Crawford",,"Data Collection-General, Mitigation",Communications of the ACM,2021,https://cacm.acm.org/magazines/2021/12/256932-datasheets-for-datasets/abstract,
61,Datasheets for datasets help ml engineers notice and understand ethical issues in training data,Karen L Boyd,,"Data Collection-General, Mitigation",CHI,2021,https://dl.acm.org/doi/abs/10.1145/3479582,
62,Automating Procedurally Fair Feature Selection in Machine Learning,"Clara Belitz, Lan Jiang,  Nigel Bosch",,"Data Preprocessing-Feature Selection, Problem Identification/Measurement",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462585,
63,Hunting for Discriminatory Proxies in Linear Regression Models,"Samuel Yeom, Anupam Datta,  Matt Fredrikson",,"Data Preprocessing-Feature Selection, Problem Identification/Mitigation",NeurIPS,2018,https://proceedings.neurips.cc/paper/2018/hash/6cd9313ed34ef58bad3fdd504355e72c-Abstract.html,
64,FlipTest: fairness testing via optimal transport,"Emily Black, Samuel Yeom,  Matt Fredrikson",,"Data Preprocessing-Feature Selection/Testing and Validation-Measurement, Problem Identification",FAccT,2020,https://dl.acm.org/doi/abs/10.1145/3351095.3372845,
65,Feature-Wise Bias Amplification,"Klas Leino, Matt Fredrikson, Emily Black, Shayak Sen,  Anupam Datta",,"Data Preprocessing-Feature Selection, Problem Identification",ICLR,2019,https://openreview.net/forum?id=S1ecm2C9K7,
66,Assessing social and intersectional biases in contextualized word representations,"Yi Chern Tan, L. Elisa Celis",,"Data Preprocessing-Feature Selection, Measurement",NeurIPS,2019,https://dl.acm.org/doi/10.5555/3454287.3455472,
67,Fairness for AUC via Feature Augmentation,"Hortense Fong, Vineet Kumar, Anay Mehrotra,  Nisheeth K. Vishnoi",,"Data Preprocessing-Feature Selection, Mitigation",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533126,
68,A Geometric Solution to Fair Representations,"Yuzi He, Keith Burghardt,  Kristina Lerman",,"Data Preprocessing-Feature Selection, Mitigation (Traditional)",AIES,2020,https://dl.acm.org/doi/10.1145/3375627.3375864,
69,Controllable invariance through adversarial feature learning,"Qizhe Xie, Zihang Dai, Yulun Du, Eduard Hovy,  Graham Neubig",,"Data Preprocessing-Data Cleaning (Omission), Measurement",NeurIPS,2017,https://dl.acm.org/doi/10.5555/3294771.3294827,
70,Data Validation for Machine Learning,"Eric Breck, Neoklis Polyzotis, Sudip Roy, Steven Whang,  Martin Zinkevich",,"Data Preprocessing-Data Cleaning (Omission), Measurement",MLSys,2019,https://mlsys.org/Conferences/2019/doc/2019/167.pdf,
71,Optimized Pre-Processing for Discrimination Prevention,"Flavio Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy,  Kush R Varshney",,"Data Preprocessing-Data Cleaning (Omission), Mitigation",NeurIPS,2017,https://papers.nips.cc/paper_files/paper/2017/hash/9a49a25d845a483fae4be7e341368e36-Abstract.html,
72,Towards Fair Deep Anomaly Detection,Hongjing Zhang  Ian Davidson,,"Data Preprocessing-Data Cleaning (Omission), Mitigation",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445878,
73,"The Data Linter: Lightweight, Automated Sanity Checking for ML Data Sets","Nick Hynes, D. Sculley,  Michael Terry",,"Data Preprocessing-Data Cleaning (Omission), Mitigation",NeurIPS ML Systems workshop,2017,http://learningsys.org/nips17/assets/papers/paper_19.pdf,
74,ActiveClean: interactive data cleaning for statistical modeling,"Sanjay Krishnan, Jiannan Wang, Eugene Wu, Michael J Franklin,  Ken Goldberg",,"Data Preprocessing-Data Cleaning (Omission), Mitigation",VLDB Endowment,2016,https://dl.acm.org/doi/10.14778/2994509.2994514,
75,"Gender Bias in Word Embeddings: A Comprehensive Analysis of Frequency, Syntax, and Semantics","Aylin Caliskan, Pimparkar Parth Ajay, Tessa Charlesworth, Robert Wolfe,  Mahzarin R. Banaji",,"Data Preprocessing-General, Problem Identification",AIES,2022,https://dl.acm.org/doi/abs/10.1145/3514094.3534162,
76,Does enforcing fairness mitigate biases caused by subpopulation shift?,"Subha Maity, Debarghya Mukherjee, Mikhail Yurochkin,  Yuekai Sun",,"Data Preprocessing-General, Problem Identification",NeurIPS,2021,https://openreview.net/forum?id=6mUrD5rg-UU,
77,Towards Understanding and Mitigating Social Biases in Language Models,"Paul Pu Liang, Chiyu Wu, Louis-Philippe Morency,  Ruslan Salakhutdinov",,"Data Preprocessing-General, Problem Identification",ICML,2021,https://proceedings.mlr.press/v139/liang21a.html,
78,Fair preprocessing: towards understanding compositional fairness of data transformers in machine learning pipeline,"Sumon Biswas, Hridesh Rajan",,"Data Preprocessing-General, Problem Identification",ESEC/FSE,2021,https://dl.acm.org/doi/10.1145/3468264.3468536,
79,Uncertainty and the Social Planner’s Problem: Why Sample Complexity Matters,Cyrus Cousins,,"Data Preprocessing-General, Measurement",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533243,
80,Promoting Fairness in Learned Models by Learning to Active Learn under Parity Constraints,"Amr Sharaf, Hal Daume III,  Renkun Ni",,"Data Preprocessing-General, Measurement",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3534632,
81,Fair Generative Modeling via Weak Supervision,"Kristy Choi, Aditya Grover, Trisha Singh, Rui Shu,  Stefano Ermon",,"Data Preprocessing-General, Measurement",ICML,2020,https://proceedings.mlr.press/v119/choi20a.html,
82,Fair Representation Learning through Implicit Path Alignment,"Changjian Shui, Qi Chen, Jiaqi Li, Boyu Wang,  Christian Gagné",,"Data Preprocessing-General, Measurement",ICML,2022,https://proceedings.mlr.press/v162/shui22a.html,
83,Understanding Instance-Level Impact of Fairness Constraints,"Jialu Wang, Xin Eric Wang,  Yang Liu",,"Data Preprocessing-General, Measurement",ICML,2022,https://proceedings.mlr.press/v162/wang22ac.html,
84,Robin Hood and Matthew Effects: Differential Privacy Has Disparate Impact on Synthetic Data,"Georgi Ganev, Bristena Oprisanu,  Emiliano De Cristofaro",,"Data Preprocessing-General, Measurement",ICML,2022,https://proceedings.mlr.press/v162/ganev22a.html,
85,Beyond Parity: Fairness Objectives for Collaborative Filtering,Sirui Yao  Bert Huang,,"Data Preprocessing-General, Mitigation",NeurIPS,2017,https://papers.nips.cc/paper_files/paper/2017/hash/e6384711491713d29bc63fc5eeb5ba4f-Abstract.html,
86,Exploiting MMD and Sinkhorn Divergences for Fair and Transferable Representation Learning,"Luca Oneto, Michele Donini, Giulia Luise, Carlo Ciliberto, Andreas Maurer,  Massimiliano Pontil",,"Data Preprocessing-General, Mitigation",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/af9c0e0c1dee63e5acad8b7ed1a5be96-Abstract.html,
87,AutoBalance: Optimized Loss Functions for Imbalanced Data,"Mingchen Li, Xuechen Zhang, Christos Thrampoulidis, Jiasi Chen,  Samet Oymak",,"Data Preprocessing-General, Mitigation",NeurIPS,2021,https://openreview.net/forum?id=ebQXflQre5a,
88,Fairness via Representation Neutralization,"Mengnan Du, Subhabrata Mukherjee, Guanchu Wang, Ruixiang Tang, Ahmed Awadallah,  Xia Hu",,"Data Preprocessing-General, Mitigation",NeurIPS,2021,https://openreview.net/forum?id=nHRGW_wETLQ,
89,Reducing sentiment polarity for demographic attributes in word embeddings using adversarial learning,"Chris Sweeney, Maryam Najafian",,"Data Preprocessing-General, Mitigation",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372837,
90,Bias in word embeddings,"Orestis Papakyriakopoulos, Simon Hegelich, Juan Carlos Medina Serrano,  Fabienne Marco",,"Data Preprocessing-General, Mitigation",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372843,
91,Smallset Timelines: A Visual Representation of Data Preprocessing Decisions,"Lydia R. Lucchesi, Petra M. Kuhnert, Jenny L. Davis,  Lexing Xie",,"Data Preprocessing-General, Mitigation",FAccT,2022,https://dl.acm.org/doi/abs/10.1145/3531146.3533175,
92,Flexibly Fair Representation Learning by Disentanglement,"Elliot Creager, David Madras, Joern-Henrik Jacobsen, Marissa Weis, Kevin Swersky, Toniann Pitassi,  Richard Zemel",,"Data Preprocessing-General, Mitigation",ICML,2019,https://proceedings.mlr.press/v97/creager19a.html,
93,DeBayes: a Bayesian Method for Debiasing Network Embeddings,"Maarten Buyl, Tijl De Bie",,"Data Preprocessing-General, Mitigation",ICML,2020,https://proceedings.mlr.press/v119/buyl20a.html,
94,Data preprocessing to mitigate bias: A maximum entropy based approach,"L. Elisa Celis, Vijay Keswani,  Nisheeth Vishnoi",,"Data Preprocessing-General, Mitigation",ICML,2020,https://proceedings.mlr.press/v119/celis20a.html,
95,On Disentangled Representations Learned from Correlated Data,"Frederik Träuble, Elliot Creager, Niki Kilbertus, Francesco Locatello, Andrea Dittadi, Anirudh Goyal, Bernhard Schölkopf,  Stefan Bauer",,"Data Preprocessing-General, Mitigation",ICML,2021,https://proceedings.mlr.press/v139/trauble21a.html,
96,Learning fair representation with a parametric integral probability metric,"Dongha Kim, Kunwoong Kim, Insung Kong, Ilsang Ohn,  Yongdai Ki",,"Data Preprocessing-General, Mitigation",ICML,2022,https://proceedings.mlr.press/v162/kim22b.html,
97,Leave-one-out Unfairness,"Emily Black, Matt Fredrikson",,"Statistical Modeling-Hypothesis Class, Problem Identification",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445894,
98,Fairness Through Robustness: Investigating Robustness Disparity in Deep Learning,"Vedant Na, Samuel Dooley, Sahil Singla, Soheil Feizi,  John P. Dickerson",,"Statistical Modeling-Hypothesis Class, Problem Identification",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445910,
99,The Rich Get Richer: Disparate Impact of Semi-Supervised Learning,"Zhaowei Zhu, Tianyi Luo,  Yang Liu",,"Statistical Modeling-Hypothesis Class, Measurement",ICLR,2022,https://openreview.net/forum?id=DXPftn5kjQK,
100,"Towards Better Detection of Biased Language with Scarce, Noisy, and Biased Annotations","Zhuoyan Li, Zhuoran Lu,  Ming Yin",,"Statistical Modeling-Hypothesis Class, Mitigation",AIES,2022,https://dl.acm.org/doi/10.1145/3514094.3534142,
101,Fair decision making using privacy-protected data,"David Pujol, Ryan McKenna, Satya Kuppam, Michael Hay, Ashwin Machanavajjhala,  Gerome Miklau",,"Statistical Modeling-Optimization Function, Problem Identification",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372872,
102,Chasing Your Long Tails: Differentially Private Prediction in Health Care Settings,"Vinith M Suriyakumar, Nicolas Papernot, Anna Goldenberg,  Marzyeh Ghassemi",,"Statistical Modeling-Optimization Function, Problem Identification",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445934,
103,Fairness Without Demographics in Repeated Loss Minimization,"Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong,  Percy Liang",,"Statistical Modeling-Optimization Function, Problem Identification",ICML,2018,https://proceedings.mlr.press/v80/hashimoto18a.html,
104,Distinguishing rule and exemplar-based generalization in learning systems,"Ishita Dasgupta, Erin Grant,  Tom Griffiths",,"Statistical Modeling-Optimization Function, Problem Identification",ICML,2022,https://proceedings.mlr.press/v162/dasgupta22b.html,
105,Underspecification Presents Challenges for Credibility in Modern Machine Learning,"Alexer D'Amour, Katherine Heller, Dan Moldovan, Ben Adlam, Babak Alipanahi, Alex Beutel, Christina Chen, Jonathan Deaton, Jacob Eisenstein, Matthew D. Hoffman, Farhad Hormozdiari, Neil Houlsby, Shaobo Hou, Ghassen Jerfel, Alan Karthikesalingam, Mario Lucic, Yian Ma, Cory McLean, Diana Mincu, Akinori Mitani, Andrea Montanari, Zachary Nado, Vivek Natarajan, Christopher Nielson, Thomas F. Osborne, Rajiv Raman, Kim Ramasamy, Rory Sayres, Jessica Schrouff, Martin Seneviratne, Shannon Sequeira, Harini Suresh, Victor Veitch, Max Vladymyrov, Xuezhi Wang, Kellie Webster, Steve Yadlowsky, Taedong Yun, Xiaohua Zhai, D. Sculley",,"Statistical Modeling-Optimization Function, Measurement",JMLR,2022,https://www.jmlr.org/papers/volume23/20-1335/20-1335.pdf,
106,To be Robust or to be Fair: Towards Fairness in Adversarial Training,"Han Xu, Xiaorui Liu, Yaxin Li, Anil Jain, Jiliang Tang",,"Statistical Modeling-Optimization Function, Mitigation",ICML,2021,https://proceedings.mlr.press/v139/xu21b.html,
107,When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness,"Chris Russell, Matt J Kusner, Joshua Loftus,  Ricardo Silva",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",NeurIPS,2017,https://papers.nips.cc/paper_files/paper/2017/hash/1271a7029c9df08643b631b02cf9e116-Abstract.html,
108,Loss-Aversively Fair Classification,"Junaid Ali, Muhammad Bilal Zafar, Adish Singla,  Krishna P. Gummadi",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314266,
109,FairEGM: Fair Link Prediction and Recommendation via Emulated Graph Modification,"Sean Current, Yuntian He, Saket Gurukar,  Srinivasan Parthasarathy",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",EAAMO,2022,https://dl.acm.org/doi/10.1145/3551624.3555287,
110,FairBatch: Batch Selection for Model Fairness,"Yuji Roh, Kangwook Lee, Steven Euijong Whang, Changho Suh",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",ICLR,2021,https://openreview.net/forum?id=YNnpaAKeCfx,
111,Achieving Equalized Odds by Resampling Sensitive Attributes,"Yaniv Romano, Stephen Bates, Emmanuel Ces",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/03593ce517feac573fdaafa6dcedef61-Abstract.html,
112,"Average individual fairness: algorithms, generalization and experiments","Saeed Sharifi-Malvajerdi, Michael Kearns,  Aaron Roth",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",NeurIPS,2019,https://dl.acm.org/doi/abs/10.5555/3454287.3455027,
113,Fair regression with wasserstein barycenters,"Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto,  Massimiliano Pontil",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",NeurIPS,2020,https://dl.acm.org/doi/abs/10.5555/3495724.3496338,
114,A Fair Classifier Using Kernel Density Estimation,"Jaewoong Cho, Gyeongjo Hwang,  Changho Suh",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/ac3870fcad1cfc367825cda0101eee62-Abstract.html,
115,Sample Selection for Fair and Robust Training,"Yuji Roh, Kangwook Lee, Steven Whang,  Changho Suh",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",NeurIPS,2021,https://openreview.net/forum?id=IZNR0RDtGp3,
116,Learning to pivot with adversarial networks,"Gilles Louppe, Michael Kagan,  Kyle Cranmer",,"Statistical Modeling-Optimization Function, Mitigation (Traditional)",NeurIPS,2017,https://dl.acm.org/doi/10.5555/3294771.3294865,
117,Tilted Empirical Risk Minimization,"Tian Li, Ahmad Beirami, Maziar Sanjabi,  Virginia Smith",,"Statistical Modeling-Optimization Function, Mitigation",ICLR,2021,https://openreview.net/forum?id=K5YasWXZT3O,
118,Gradient Driven Rewards to Guarantee Fairness in Collaborative Machine Learning,"Xinyi Xu, Lingjuan Lyu, Xingjun Ma, Chenglin Miao, Chuan Sheng Foo,  Bryan Kian Hsiang Low",,"Statistical Modeling-Optimization Function, Mitigation",NeurIPS,2021,https://openreview.net/forum?id=yRfsADObu18,
119,Matching Learned Causal Effects of Neural Networks with Domain Priors,"Sai Srinivas Kancheti, Abbavaram Gowtham Reddy, Vineeth N Balasubramanian,  Amit Sharma",,"Statistical Modeling-Regularizers, Mitigation",ICML,2022,https://proceedings.mlr.press/v162/kancheti22a.html,
120,Selective Regression under Fairness Criteria,"Abhin Shah, Yuheng Bu, Joshua K Lee, Subhro Das, Rameswar Pa, Prasanna Sattigeri,  Gregory W Wornell",,"Statistical Modeling-Regularizers, Mitigation",ICML,2022,https://proceedings.mlr.press/v162/shah22a.html,
121,When Trusted Black Boxes Don't Agree: Incentivizing Iterative Improvement and Accountability in Critical Software Systems,"Jeanna Neefe Matthews, Graham Northup, Isabella Grasso, Stephen Lorenz, Marzieh Babaeianjelodar, Hunter Bashaw, Sumona Mondal, Abigail Matthews, Mariama Njie, Jessica Goldthwaite",,"Statistical Modeling-Hyperparameters, Problem Identification",AIES,2020,https://dl.acm.org/doi/10.1145/3375627.3375807,
122,Can Information Flows Suggest Targets for Interventions in Neural Circuits?,"Praveen Venkatesh, Sanghamitra Dutta, Neil Mehta,  Pulkit Grover",,"Statistical Modeling-Hyperparameters, Mitigation",NeurIPS,2021,https://openreview.net/forum?id=jBQaRXpEgO,
123,GetFair: Generalized Fairness Tuning of Classification Models,"Sipan Sikdar, Florian Lemmerich,  Markus Strohmaier",,"Statistical Modeling-Hyperparameters, Mitigation",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533094,
124,Multi-objective multi-fidelity hyperparameter optimization with application to fairness,"Robin Schmucker, Michele Donini, Valerio Perrone,  Cédric Archambeau",,"Statistical Modeling-Hyperparameters, Mitigation",NeurIPS workshop on Meta-learning,2020,https://www.amazon.science/publications/multi-objective-multi-fidelity-hyperparameter-optimization-with-application-to-fairness,
125,Can We Obtain Fairness For Free?,"Rashidul Islam, Shimei Pan,  James R Foulds",,"Statistical Modeling-Hyperparameters, Mitigation",AIES,2021,https://dl.acm.org/doi/abs/10.1145/3461702.3462614,
126,Fair Bayesian Optimization,"Valerio Perrone, Michele Donini, Muhammad Bilal Zafar, Robin Schmucker, Krishnaram Kenthapadi,  Cédric Archambeau",,"Statistical Modeling-Hyperparameters, Mitigation",AIES,2021,https://dl.acm.org/doi/abs/10.1145/3461702.3462629,
127,Subgroup Generalization and Fairness of Graph Neural Networks,"Jiaqi Ma, Junwei Deng,  Qiaozhu Mei",,"Statistical Modeling-General, Problem Identification",NeurIPS,2021,https://openreview.net/forum?id=68B1ezcffDc,
128,Measuring Fairness of Rankings under Noisy Sensitive Information,"Azin Ghazimatin, Matthaus Kleindessner, Chris Russell, Ziawasch Abedjan,  Jacek Golebiowski",,"Statistical Modeling-General, Problem Identification",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3534641,
129,Too Relaxed to Be Fair,"Michael Lohaus, Michael Perrot,  Ulrike Von Luxburg",,"Statistical Modeling-General, Problem Identification",ICML,2020,https://proceedings.mlr.press/v119/lohaus20a.html,
130,Characterizing Fairness Over the Set of Good Models Under Selective Labels,"Ama Coston, Ashesh Rambachan,  Alexra Chouldechova",,"Statistical Modeling-General, Problem Identification",ICML,2021,https://proceedings.mlr.press/v139/coston21a.html,
131,"Putting Fairness Principles into Practice: Challenges, Metrics, and Improvements","Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Allison Woodruff, Christine Luu, Pierre Kreitmann, Jonathan Bischof,  Ed H. Ch",,"Statistical Modeling-General, Problem Identification",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314234,
132,A Sandbox Tool to Bias(Stress)-Test Fairness Algorithms,"Nil-Jana Akpinar, Manish Nagireddy, Logan Stapleton, Hao-Fei Cheng, Haiyi Zhu, Steven Wu,  Hoda Heidari",,"Statistical Modeling-General, Problem Identification",EAAMO,2022,https://arxiv.org/abs/2204.10233,
133,Differential privacy has disparate impact on model accuracy,"Eugene Bagdasaryan, Omid Poursaeed,  Vitaly Shmatikov",,"Statistical Modeling-General, Problem Identification",NeurIPS,2019,https://dl.acm.org/doi/abs/10.5555/3454287.3455674,
134,"Fair, Robust, and Data-Efficient Machine Learning in Healthcare",Harvineet Singh,,"Statistical Modeling-General, Problem Identification (Case Study)",AIES,2022,https://dl.acm.org/doi/10.1145/3514094.3539552,
135,Learning the Pareto Front with Hypernetworks,"Aviv Navon, Aviv Shamsian, Ethan Fetaya,  Gal Chechik",,"Statistical Modeling-General, Measurement",NeurIPS,2021,https://openreview.net/forum?id=NjF772F4ZZR,
136,Fairness Under Unawareness: Assessing Disparity When Protected Class Is Unobserved,"Jiahao Chen, Nathan Kallus, Xiaojie Mao, Geoffry Svacha,  Madeleine Udell",,"Statistical Modeling-General, Measurement",FAccT,2019,https://dl.acm.org/doi/10.1145/3287560.3287594,
137,POTs: protective optimization technologies,"Bogdan Kulynych, Rebekah Overdorf, Carmela Troncoso,  Seda Gürses",,"Statistical Modeling-General, Measurement",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372853,
138,Directional Bias Amplification,"Angelina Wang, Olga Russakovsky",,"Statistical Modeling-General, Measurement",ICML,2021,https://proceedings.mlr.press/v139/wang21t.html,
139,On the Tradeoff Between Robustness and Fairness,"Xinsong Ma, Zekai Wang,  Weiwei Liu",,"Statistical Modeling-General, Measurement",NeurIPS,2022,https://openreview.net/forum?id=LqGA2JMLwBw,
140,Refining Language Models with Compositional Explanations,"Huihan Yao, Ying Chen, Qinyuan Ye, Xisen Jin,  Xiang Ren",,"Statistical Modeling-General, Mitigation",NeurIPS,2021,https://openreview.net/forum?id=dkw9OQMn1t,
141,Noise-tolerant fair classification,"Alex Lamy, Ziyuan Zhong, Aditya K Menon,  Nakul Verma",,"Statistical Modeling-General, Mitigation",NeurIPS,2019,https://dl.acm.org/doi/10.5555/3454287.3454314,
142,Learning certified individually fair representations,"Anian Ruoss, Mislav Balunovic, Marc Fischer,  Martin Vechev",,"Statistical Modeling-General, Mitigation",NeurIPS,2020,https://dl.acm.org/doi/10.5555/3495724.3496360,
143,On Dyadic Fairness: Exploring and Mitigating Bias in Graph Connections,"Peizhao Li, Yifei Wang, Han Zhao, Pengyu Hong,  Hongfu Liu",,"Statistical Modeling-General, Mitigation",ICLR,2021,https://openreview.net/forum?id=xgGS6PmzNq6,
144,Fair Normalizing Flows,"Mislav Balunovic, Anian Ruoss,  Martin Vechev",,"Statistical Modeling-General, Mitigation",ICLR,2022,https://openreview.net/forum?id=BrFIKuxrZE,
145,Decoupled Classifiers for Group-Fair and Efficient Machine Learning,"Cynthia Dwork, Nicole Immorlica, Adam Tauman Kalai,  Max Leiserson",,"Statistical Modeling-General, Mitigation",FAccT,2018,https://proceedings.mlr.press/v81/dwork18a.html,
146,Recommendation Independence,"Toshihiro Kamishima, Shotaro Akaho, Hideki Asoh,  Jun Sakuma",,"Statistical Modeling-General, Mitigation",FAccT,2018,https://proceedings.mlr.press/v81/kamishima18a.html,
147,Balanced Neighborhoods for Multi-sided Fairness in Recommendation,"Robin Burke, Nasim Sonboli,  Aldo Ordonez-Gauger",,"Statistical Modeling-General, Mitigation",FAccT,2018,https://proceedings.mlr.press/v81/burke18a.html,
148,Mitigating Bias in Set Selection with Noisy Protected Attributes,"Anay Mehrotra, L. Elisa Celis",,"Statistical Modeling-General, Mitigation",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445887,
149,Achieving Fairness via Post-Processing in Web-Scale Recommender Systems,"Preetam Ny, Cyrus DiCiccio, Divya Venugopalan, Heloise Logan, Kinjal Basu,  Noureddine El Karoui",,"Statistical Modeling-General, Mitigation",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533136,
150,Learning Optimal Fair Policies,"Razieh Nabi, Daniel Malinsky,  Ilya Shpitser",,"Statistical Modeling-General, Mitigation",ICML,2019,https://proceedings.mlr.press/v97/nabi19a.html,
151,"Contrastive Mixture of Posteriors for Counterfactual Inference, Data Integration and Fairness","Adam Foster, Arpi Vezer, Craig A. Glastonbury, Paidi Creed, Samer Abujudeh,  Aaron Sim",,"Statistical Modeling-General, Mitigation",ICML,2022,https://proceedings.mlr.press/v162/foster22a.html,
152,Mitigating Unwanted Biases with Adversarial Learning,"Brian Hu Zhang, Blake Lemoine,  Margaret Mitchell",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2018,https://dl.acm.org/doi/10.1145/3278721.3278779,
153,Multiaccuracy: Black-Box Post-Processing for Fairness in Classification,"Michael P. Kim, Amirata Ghorbani,  James Zou",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314287,
154,FaiR-N: Fair and Robust Neural Networks for Structured Data,"Shubham Sharma, Alan H. Gee, David Paydarfar,  Joydeep Ghosh",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462559,
155,Mitigating Racial Biases in Toxic Language Detection with an Equity-Based Ensemble Framework,"Matan Halevy, Camille Harris, Amy Bruckman, Diyi Yang,  Ayanna Howard",,"Statistical Modeling-General, Mitigation (Traditional)",EAAMO,2021,https://dl.acm.org/doi/10.1145/3465416.3483299,
156,Fairness without Demographics through Adversarially Reweighted Learning,"Preethi Lahoti, Alex Beutel, Jilin Chen, Kang Lee, Flavien Prost, Nithum Thain, Xuezhi Wang,  Ed Chi",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/07fc15c9d169ee48573edd749d25945d-Abstract.html,
157,Post-processing for Individual Fairness,"Felix Petersen, Debarghya Mukherjee, Yuekai Sun,  Mikhail Yurochkin",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2021,https://openreview.net/forum?id=qGeqg4_hA2,
158,Conditional Learning of Fair Representations,"Han Zhao, Ama Coston, Tameem Adel,  Geoffrey J. Gordon",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2020,https://openreview.net/forum?id=Hkekl0NFPr,
159,FairCal: Fairness Calibration for Face Verification,"Tiago Salvador, Stephanie Cairns, Vikram Voleti, Noah Marshall,  Adam M Oberman",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2022,https://openreview.net/forum?id=nRj0NcmSuxb,
160,Providing Item-side Individual Fairness for Deep Recommender Systems,"Xiuling Wang, Wendy Hui Wang",,"Statistical Modeling-General, Mitigation (Traditional)",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533079,
161,FADE: FAir Double Ensemble Learning for Observable and Counterfactual Outcomes,"Alan Mishler, Edward H. Kennedy",,"Statistical Modeling-General, Mitigation (Traditional)",FAccT,2022,https://doi.org/10.1145/3531146.3533167,
162,Fairness-aware Model-agnostic Positive and Unlabeled Learning,"Ziwei Wu, Jingrui He",,"Statistical Modeling-General, Mitigation (Traditional)",FAccT,2022,https://dl.acm.org/doi/abs/10.1145/3531146.3533225,
163,A Reductions Approach to Fair Classification,"Alekh Agarwal, Alina Beygelzimer, Miroslav Dudik, John Langford,  Hanna Wallach",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2018,https://proceedings.mlr.press/v80/agarwal18a.html,
164,Blind Justice: Fairness with Encrypted Sensitive Attributes,"Niki Kilbertus, Adria Gascon, Matt Kusner, Michael Veale, Krishna Gummadi,  Adrian Weller",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2018,https://proceedings.mlr.press/v80/kilbertus18a.html,
165,Learning Adversarially Fair and Transferable Representations,"David Madras, Elliot Creager, Toniann Pitassi,  Richard Zemel",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2018,https://proceedings.mlr.press/v80/madras18a.html,
166,Fair Mixup: Fairness via Interpolation,"Ching-Yao Chuang, Youssef Mroueh",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2021,https://openreview.net/forum?id=DNl5s5BXeBn,
167,Classification with Fairness Constraints: A Meta-Algorithm with Provable Guarantees,"L Elisa Celis, Lingxiao Huang, Vijay Keswani,  Nisheeth K Vishnoi",,"Statistical Modeling-General, Mitigation (Traditional)",FAccT,2019,https://dl.acm.org/doi/10.1145/3287560.3287586,
168,Counterfactual Fairness in Text Classification through Robustness,"Sahaj Garg, Vincent Perot, Nicole Limtiaco, Ankur Taly, Ed H. Chi,  Alex Beutel",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3317950,
169,Nonconvex Optimization for Regression with Fairness Constraints,"Junpei Komiyama, Akiko Takeda, Junya Honda,  Hajime Shimao",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2018,https://proceedings.mlr.press/v80/komiyama18a.html,
170,Taking Advantage of Multitask Learning for Fair Classification,"Luca Oneto, Michele Doninini, Amon Elders,  Massimiliano Pontil",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314255,
171,Accounting for Model Uncertainty in Algorithmic Discrimination,"Junaid Ali, Preethi Lahoti,  Krishna P. Gummadi",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462630,
172,Marrying Fairness and Explainability in Supervised Learning,"Przemyslaw A. Grabowicz, Nicholas Perello,  Aarshee Mishra",,"Statistical Modeling-General, Mitigation (Traditional)",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533236,
173,"It’s Not Fairness, and It’s Not Fair: The Failure of Distributional Equality and the Promise of Relational Equality in Complete-Information Hiring Games","Benjamin Fish, Luke Stark",,"Statistical Modeling-General, Mitigation (Traditional)",EAAMO,2022,https://dl.acm.org/doi/10.1145/3551624.3555296,
174,A Just Approach Balancing Rawlsian Leximax Fairness and Utilitarianism,"Violet (Xinying) Chen, J. N. Hooker",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2020,https://dl.acm.org/doi/10.1145/3375627.3375844,
175,An Algorithmic Framework for Positive Action,"Oliver Thomas, Miri Zilka, Adrian Weller,  Novi Quadrianto",,"Statistical Modeling-General, Mitigation (Traditional)",EAAMO,2021,https://dl.acm.org/doi/10.1145/3465416.3483303,
176,Recycling privileged learning and distribution matching for fairness,"Novi Quadrianto, Viktoriia Sharmanska",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2017,https://dl.acm.org/doi/abs/10.5555/3294771.3294836,
177,Counterfactual Fairness,"Matt J Kusner, Joshua Loftus, Chris Russell,  Ricardo Silva",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2017,https://dl.acm.org/doi/10.5555/3294996.3295162,
178,Empirical risk minimization under fairness constraints,"Michele Donini, Luca Oneto, Shai Ben-David, John S Shawe-Taylor,  Massimiliano Pontil",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2018,https://dl.acm.org/doi/10.5555/3327144.3327203,
179,Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making,"Hoda Heidari, Claudio Ferrari, Krishna Gummadi,  Andreas Krause",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2018,https://papers.nips.cc/paper_files/paper/2018/hash/be3159ad04564bfb90db9e32851ebf9c-Abstract.html,
180,Individually Fair Rankings,"Ama Bower, Hamid Eftekhari, Mikhail Yurochkin,  Yuekai Sun",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2021,https://openreview.net/forum?id=71zCSP%5FHuBN,
181,Individually Fair Gradient Boosting,"Alexer Vargo, Fan Zhang, Mikhail Yurochkin,  Yuekai Sun",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2021,https://openreview.net/forum?id=JBAa9we1AL,
182,SenSeI: Sensitive Set Invariance for Enforcing Individual Fairness,"Mikhail Yurochkin, Yuekai Sun",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2021,https://openreview.net/forum?id=DktZb97%5FFx,
183,Controlling Directions Orthogonal to a Classifier,"Yilun Xu, Hao He, Tianxiao Shen,  Tommi S. Jaakkola",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2022,https://openreview.net/forum?id=DIjCrlsu6Z,
184,Offline Contextual Bandits with High Probability Fairness Guarantees,"Blossom Metevier, Stephen Giguere, Sarah Brockman, Ari Kobren, Yuriy Brun, Emma Brunskill,  Philip S. Thomas",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2019,https://papers.nips.cc/paper_files/paper/2019/hash/d69768b3da745b77e82cdbddcc8bac98-Abstract.html,
185,Approximate Heavily-Constrained Learning with Lagrange Multiplier Models,"Harikrishna Narasimhan, Andrew Cotter, Yichen Zhou, Serena Wang,  Wenshuo Guo",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/62db9e3397c76207a687c360e0243317-Abstract.html,
186,Group-Fair Online Allocation in Continuous Time,"Semih Cayci, Swati Gupta,  Atilla Eryilmaz",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/9ec0cfdc84044494e10582436e013e64-Abstract.html,
187,Fairness Violations and Mitigation under Covariate Shift,"Harvineet Singh, Rina Singh, Vishwali Mhasawade,  Rumi Chunara",,"Statistical Modeling-General/Deployment and Integration-General, Mitigation (Traditional)",FAccT,2021,https://doi.org/10.1145/3351095.3372839,
188,Fair Algorithms for Learning in Allocation Problems,"Hadi Elzayn, Shahin Jabbari, Christopher Jung, Michael Kearns, Seth Neel, Aaron Roth,  Zachary Schutzman",,"Statistical Modeling-General, Mitigation (Traditional)",FAccT,2019,https://dl.acm.org/doi/10.1145/3287560.3287571,
189,Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness,"Michael Kearns, Seth Neel, Aaron Roth,  Zhiwei Steven Wu",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2018,https://proceedings.mlr.press/v80/kearns18a.html,
190,Probably Approximately Metric-Fair Learning,"Gal Yona, Guy Rothblum",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2018,https://proceedings.mlr.press/v80/yona18a.html,
191,Training Well-Generalizing Classifiers for Fairness Metrics and Other Data-Dependent Constraints,"Andrew Cotter, Maya Gupta, Heinrich Jiang, Nathan Srebro, Karthik Sridharan, Serena Wang, Blake Woodworth,  Seungil You",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2019,https://proceedings.mlr.press/v97/cotter19b.html,
192,Non-Discriminatory Machine Learning through Convex Fairness Criteria,"Naman Goel, Mohammad Yaghini,  Boi Faltings",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2018,https://dl.acm.org/doi/10.1145/3278721.3278722,
193,Fair Forests: Regularized Tree Induction to Minimize Model Bias,"Edward Raff, Jared Sylvester,  Steven Mills",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2018,https://dl.acm.org/doi/10.1145/3278721.3278742,
194,RAWLSNET: Altering Bayesian Networks to Encode Rawlsian Fair Equality of Opportunity,"David Liu, Zohair Shafi, William Fleisher, Tina Eliassi-Rad,  Scott Alfeld",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462618,
195,Rawlsian Fair Adaptation of Deep Learning Classifiers,"Kulin Shah, Pooja Gupta, Amit Deshpe,  Chiranjib Bhattacharyya",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462592,
196,On Human-Aligned Risk Minimization,"Liu Leqi, Adarsh Prasad,  Pradeep K Ravikumar",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2019,https://papers.nips.cc/paper_files/paper/2019/hash/cd6b73b67c77edeaff94e24b961119dd-Abstract.html,
197,Fair regression via plug-in estimator and recalibration with statistical guarantees,"Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto,  Massimiliano Pontil",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/ddd808772c035aed516d42ad3559be5f-Abstract.html,
198,Metric-free individual fairness in online learning,"Yahav Bechavod, Christopher Jung,  Zhiwei Steven Wu",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2020,https://dl.acm.org/doi/10.5555/3495724.3496665,
199,Two-sided fairness in rankings via Lorenz dominance,"Virginie Do, Sam Corbett-Davies, Jamal Atif,  Nicolas Usunier",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2021,https://proceedings.neurips.cc/paper/2021/hash/48259990138bc03361556fb3f94c5d45-Abstract.html,
200,Fairness in Risk Assessment Instruments: Post-Processing to Achieve Counterfactual Equalized Odds,"Alan Mishler, Edward H. Kennedy,  Alexra Chouldechova",,"Statistical Modeling-General, Mitigation (Traditional)",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445902,
201,Fast online ranking with fairness of exposure,"Nicolas Usunier, Virginie Do,  Elvis Dohmatob",,"Statistical Modeling-General, Mitigation (Traditional)",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3534633,
202,Multicalibration: Calibration for the (Computationally-Identifiable) Masses,"Ursula Hebert-Johnson, Michael Kim, Omer Reingold,  Guy Rothblum",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2018,https://proceedings.mlr.press/v80/hebert-johnson18a.html,
203,Fair Regression: Quantitative Definitions and Reduction-Based Algorithms,"Alekh Agarwal, Miroslav Dudik,  Zhiwei Steven W",,"Statistical Modeling-General, Mitigation (Traditional)",ICML,2019,https://proceedings.mlr.press/v97/agarwal19d.html,
204,Unlocking fairness: a trade-off revisited,"Michael Wick, Swetasudha Pa,  Jean-Baptiste Tristan",,"Statistical Modeling-General, Mitigation",NeurIPS,2019,https://dl.acm.org/doi/10.5555/3454287.3455075,
205,Fairness in Relational Domains,"Golnoosh Farnadi, Behrouz Babaki,  Lise Getoor",,"Statistical Modeling-General, Mitigation (Traditional)",AIES,2018,https://dl.acm.org/doi/10.1145/3278721.3278733,
206,Near Neighbor: Who is the Fairest of Them All?,"Sariel Har-Peled, Sepideh Mahabadi",,"Statistical Modeling-General, Mitigation (Traditional)",NeurIPS,2019,https://papers.nips.cc/paper_files/paper/2019/hash/742141ceda6b8f6786609d31c8ef129f-Abstract.html,
207,Rényi Fair Inference,"Sina Baharlouei, Maher Nouiehed, Ahmad Beirami,  Meisam Razaviyayn",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2020,https://openreview.net/forum?id=HkgsUJrtDB,
208,Training individually fair ML models with sensitive subspace robustness,"Mikhail Yurochkin, Ama Bower,  Yuekai Sun",,"Statistical Modeling-General, Mitigation (Traditional)",ICLR,2020,https://openreview.net/forum?id=B1gdkxHFDH,
209,Certifying Robustness to Programmable Data Bias in Decision Trees,"Anna Meyer, Aws Albarghouthi,  Loris D' Antoni",,"Statistical Modeling-General, Mitigation",NeurIPS,2021,https://proceedings.neurips.cc/paper/2021/hash/dcf531edc9b229acfe0f4b87e1e278dd-Abstract.html,
210,Fair Performance Metric Elicitation,"Gaurush Hiranani, Harikrishna Narasimhan,  Sanmi Koyejo",,"Testing and Validation-Evaluation Metrics, Problem Identification",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/7ec2442aa04c157590b2fa1a7d093a33-Abstract.html,
211,Is Fairness Only Metric Deep? Evaluating and Addressing Subgroup Gaps in Deep Metric Learning,"Natalie Dullerud, Karsten Roth, Kimia Hamidieh, Nicolas Papernot,  Marzyeh Ghassemi",,"Testing and Validation-Evaluation Metrics, Problem Identification",ICLR,2022,https://openreview.net/forum?id=js62%5FxuLDDv,
212,"Model Multiplicity: Opportunities, Concerns, and Solutions","Emily Black, Manish Raghavan,  Solon Barocas",,"Testing and Validation-Evaluation Metrics, Problem Identification",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533149,
213,Affirmative Algorithms: Relational Equality as Algorithmic Fairness,Marilyn Zhang,,"Testing and Validation-Evaluation Metrics, Problem Identification (Traditional)",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533115,
214,Fair Sequential Selection Using Supervised Learning Models,"Mohammad Mahdi Khalili, Xueru Zhang,  Mahed Abroshan",,"Testing and Validation-Evaluation Metrics, Problem Identification",NeurIPS,2021,https://proceedings.neurips.cc/paper/2021/hash/ed277964a8959e72a0d987e598dfbe72-Abstract.html,
215,Fairness Criteria for Face Recognition Applications,Filip Michalsky,,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314308,
216,CERTIFAI: A Common Framework to Provide Explanations and Analyse the Fairness and Robustness of Black-box Models,"Shubham Sharma, Jette Henderson,  Joydeep Ghosh",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",AIES,2020,https://dl.acm.org/doi/10.1145/3375627.3375812,
217,Minimax Group Fairness: Algorithms and Experiments,"Emily Diana, Wesley Gill, Michael Kearns, Krishnaram Kenthapadi,  Aaron Roth",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462523,
218,Fairness through computationally-bounded awareness,"Michael Kim, Omer Reingold,  Guy Rothblum",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",NeurIPS,2018,https://dl.acm.org/doi/10.5555/3327345.3327393,
219,Equality of Opportunity in Classification: A Causal Approach,"Junzhe Zhang, Elias Bareinboim",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",NeurIPS,2018,https://papers.nips.cc/paper_files/paper/2018/hash/ff1418e8cc993fe8abcfe3ce2003e5c5-Abstract.html,
220,The fairness of risk scores beyond classification: bipartite ranking and the xAUC metric,"Nathan Kallus, Angela Zhou",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",NeurIPS,2019,https://dl.acm.org/doi/10.5555/3454287.3454596,
221,Model class reliance for random forests,"Gavin Smith, Roberto Mansilla,  James Goulding",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",NeurIPS,2020,https://dl.acm.org/doi/10.5555/3495724.3497594,
222,Statistical inference for individual fairness ,"Subha Maity, Songkai Xue, Mikhail Yurochkin,  Yuekai Sun",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",ICLR,2021,https://openreview.net/forum?id=z9k8BWL-%5F2u,
223,Generalized Demographic Parity for Group Fairness ,"Zhimeng Jiang, Xiaotian Han, Chao Fan, Fan Yang, Ali Mostafavi,  Xia Hu",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",ICLR,2022,https://openreview.net/forum?id=YigKlMJwjye,
224,Measuring Fairness in an Unfair World,Jonathan Herington,,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",AIES,2020,https://dl.acm.org/doi/10.1145/3375627.3375854,
225,An Axiomatic Theory of Provably-Fair Welfare-Centric Machine Learning,Cyrus Cousins,,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",NeurIPS,2021,https://proceedings.neurips.cc/paper/2021/hash/8b0bb3eff8c1e5bf7f206125959921d7-Abstract.html,
226,"Counterfactual risk assessments, evaluation, and fairness","Ama Coston, Alan Mishler, Edward H. Kennedy,  Alexra Chouldechova",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372851,
227,Counterfactual Fairness in Text Classification through Robustness,"Sahaj Garg, Vincent Perot, Nicole Limtiaco, Ankur Taly, Ed H. Chi,  Alex Beutel",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3317950,
228,Contrastive Counterfactual Fairness in Algorithmic Decision-Making,"Ece Çiğdem Mutlu, Niloofar Yousefi,  Ozlem Ozmen Garibay",,"Testing and Validation-Evaluation Metrics, Measurement (Traditional)",AIES,2022,https://dl.acm.org/doi/10.1145/3514094.3534143,
229,Evaluating Fairness of Machine Learning Models Under Uncertain and Incomplete Information,"Pranjal Awasthi, Alex Beutel, Matthäus Kleindessner, Jamie Morgenstern,  Xuezhi Wang",,"Testing and Validation-Evaluation Metrics, Measurement",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445884,
230,A Statistical Test for Probabilistic Fairness,"Bahar Taskesen, Jose Blanchet, Daniel Kuhn,  Viet Anh Nguyen",,"Testing and Validation-Evaluation Metrics, Measurement",FAccT,2021,https://dl.acm.org/doi/10.1145/3442188.3445927,
231,An Outcome Test of Discrimination for Ranked Lists,"Jonathan Roth, Guillaume Saint-Jacques,  YinYin Yu",,"Testing and Validation-Evaluation Metrics, Measurement",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533102,
232,Active fairness auditing,"Tom Yan, Chicheng Zhang",,"Testing and Validation-Evaluation Metrics, Measurement",ICML,2022,https://proceedings.mlr.press/v162/yan22c.html,
233,Invariant Representations without Adversarial Training,"Daniel Moyer, Shuyang Gao, Rob Brekelmans, Aram Galstyan,  Greg Ver Steeg",,"Testing and Validation-Evaluation Metrics, Mitigation",NeurIPS,2018,https://papers.nips.cc/paper_files/paper/2018/hash/415185ea244ea2b2bedeb0449b926802-Abstract.html,
234,Causal Multi-level Fairness,"Vishwali Mhasawade, Rumi Chunara",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462587,
235,From parity to preference-based notions of fairness in classification,"Muhammad Bilal Zafar, Isabel Valera, Manuel Rodriguez, Krishna Gummadi,  Adrian Weller",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2017,https://dl.acm.org/doi/abs/10.5555/3294771.3294793,
236,Avoiding discrimination through causal reasoning,"Niki Kilbertus, Mateo Rojas Carulla, Giambattista Parascolo, Moritz Hardt, Dominik Janzing,  Bernhard Schölkopf",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2017,https://dl.acm.org/doi/10.5555/3294771.3294834,
237,From Soft Classifiers to Hard Decisions: How fair can we be?,"Ran Canetti, Aloni Cohen, Nishanth Dikkala, Govind Ramnarayan, Sarah Scheffler,  Adam Smith",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",FAccT,2019,https://dl.acm.org/doi/10.1145/3287560.3287561,
238,Leveraging Labeled and Unlabeled Data for Consistent Fair Binary Classification,"Evgenii Chzhen, Christophe Denis, Mohamed Hebiri, Luca Oneto,  Massimiliano Pontil",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2019,https://proceedings.neurips.cc/paper_files/paper/2019/hash/ba51e6158bcaf80fd0d834950251e693-Abstract.html,
239,Envy-Free Classification,"Maria-Florina F Balcan, Travis Dick, Ritesh Noothigattu,  Ariel D Procaccia",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2019,https://papers.nips.cc/paper_files/paper/2019/hash/e94550c93cd70fe748e6982b3439ad3b-Abstract.html,
240,Fairness with Overlapping Groups; a Probabilistic Perspective,"Forest Yang, Mouhamadou Cisse,  Sanmi Koyejo",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/29c0605a3bab4229e46723f89cf59d83-Abstract.html,
241,"Classification Under Misspecification: Halfspaces, Generalized Linear Models, and Evolvability","Sitan Chen, Frederic Koehler, Ankur Moitra,  Morris Yau",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2020,https://proceedings.neurips.cc/paper/2020/hash/5f8b73c0d4b1bf60dd7173b660b87c29-Abstract.html,
242,Incorporating Interpretable Output Constraints in Bayesian Neural Networks,"Wanqian Yang, Lars Lorch, Moritz Graule, Himabindu Lakkaraju,  Finale Doshi-Velez",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2020,https://proceedings.neurips.cc/paper_files/paper/2020/hash/95c7dfc5538e1ce71301cf92a9a96bd0-Abstract.html,
243,Efficient Mirror Descent Ascent Methods for Nonsmooth Minimax Problems,"Feihu Huang, Xidong Wu,  Heng Huang",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2021,https://openreview.net/forum?id=3EuMT2Lqn4q,
244,Scalable and Stable Surrogates for Flexible Classifiers with Fairness Constraints,"Henry C Bendekgey, Erik Sudderth",,"Testing and Validation-Evaluation Metrics, Mitigation (Case Study)",NeurIPS,2021,https://proceedings.neurips.cc/paper/2021/hash/fc2e6a440b94f64831840137698021e1-Abstract.html,
245,Design of Experiments for Model Discrimination Hybridising Analytical and Data-Driven Approaches,"Simon Olofsson, Marc Deisenroth,  Ruth Misener",,"Testing and Validation-General, Problem Identification (Case Study)",ICML,2018,https://proceedings.mlr.press/v80/olofsson18a.html,
246,Testing Group Fairness via Optimal Transport Projections,"Nian Si, Karthyek Murthy, Jose Blanchet,  Viet Anh Nguyen",,"Testing and Validation-General, Problem Identification",ICML,2021,https://proceedings.mlr.press/v139/si21a.html,
247,De-biasing “bias” measurement,"Kristian Lum, Yunfeng Zhang,  Ama Bower",,"Testing and Validation-General, Measurement",FAccT,2022,https://dl.acm.org/doi/abs/10.1145/3531146.3533105,
248,"AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and Mitigating Unwanted Algorithmic Bias","Rachel K. E. Bellamy, Kuntal Dey, Michael Hind, Samuel C. Hoffman, Stephanie Houde, Kalapriya Kannan, Pranay Lohia, Jacquelyn Martino, Sameep Mehta, Aleksra Mojsilovic, Seema Nagar, Karthikeyan Natesan Ramamurthy, John Richards, Diptikalyan Saha, Prasanna Sattigeri, Moninder Singh, Kush R. Varshney, Yunfeng Zhang",,"Testing and Validation-General, Measurement",,2018,https://arxiv.org/abs/1810.01943,
249,Amazon SageMaker Clarify: Machine Learning Bias Detection and Explainability in the Cloud,"Michaela Hardt, Xiaoguang Chen, Xiaoyi Cheng, Michele Donini, Jason Gelman, Satish Gollaprolu, John He, Pedro Larroy, Xinyu Liu, Nick McCarthy, Ashish Rathi, Scott Rees, Ankit Siva, ErhYuan Tsai, Keerthan Vasist, Pinar Yilmaz, Muhammad Bilal Zafar, Sanjiv Das, Kevin Haas, Tyler Hill, Krishnaram Kenthapadi",,"Testing and Validation-General, Measurement",,2021,https://arxiv.org/abs/2109.03285,
250,Data and its (dis)contents: A survey of dataset development and use in machine learning research,"Amalynne Paullada, Inioluwa Deborah Raji, Emily M Bender, Emily Denton,  Alex Hanna",,"Testing and Validation-General, Measurement",Patterns,2021,https://www.sciencedirect.com/science/article/pii/S2666389921001847,
251,Aequitas: A Bias and Fairness Audit Toolkit,"Pedro Saleiro, Benedict Kuester, Loren Hinkson, Jesse London, Abby Stevens, Ari Anisfeld, Kit T Rodolfa,  Rayid Ghani.",,"Testing and Validation-General, Measurement",,2018,https://arxiv.org/abs/1811.05577,
252,Preference-informed fairness,"Michael P. Kim, Aleksra Korolova, Guy N. Rothblum,  Gal Yon",,"Testing and Validation-General, Measurement (Traditional)",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3373155,
253,Fair Transfer Learning with Missing Protected Attributes,"Ama Coston, Karthikeyan Natesan Ramamurthy, Dennis Wei, Kush R. Varshney, Skyler Speakman, Zairah Mustahsan,  Supriyo Chakraborty",,"Testing and Validation-General/Deployment and Integration-General, Mitigation",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314236,
254,Measuring and Mitigating Unintended Bias in Text Classification,"Lucas Dixon, John Li, Jeffrey Sorensen, Nithum Thain,  Lucy Vasserman",,"Testing and Validation-General, Mitigation",AIES,2018,https://dl.acm.org/doi/10.1145/3278721.3278729,
255,FairFil: Contrastive Neural Debiasing Method for Pretrained Text Encoders ,"Pengyu Cheng, Weituo Hao, Siyang Yuan, Shijing Si,  Lawrence Carin",,"Testing and Validation-General, Mitigation",ICLR,2021,https://openreview.net/forum?id=N6JECD-PI5w,
256,Repairing without Retraining: Avoiding Disparate Impact with Counterfactual Distributions,"Hao Wang, Berk Ustun,  Flavio Calmon",,"Testing and Validation-General, Mitigation",ICML,2022,https://proceedings.mlr.press/v97/wang19l.html,
257,How machine-learning recommendations influence clinician treatment selections: the example of antidepressant selection,"Maia Jacobs, Melanie F Pradier, Thomas H McCoy Jr, Roy H Perlis, Finale Doshi-Velez,  Krzysztof Z Gajos",,"Deployment and Integration-Human/Computer Handoff, Problem Identification (Case Study)",Nature Translational Psychiatry,2021,https://www.nature.com/articles/s41398-021-01224-x,
258,Towards Unbiased and Accurate Deferral to Multiple Experts,"Vijay Keswani, Matthew Lease,  Krishnaram Kenthapadi",,"Deployment and Integration-Human/Computer Handoff, Problem Identification",AIES,2021,https://dl.acm.org/doi/10.1145/3461702.3462516,
259,Disparate Interactions: An Algorithm-in-the-Loop Analysis of Fairness in Risk Assessments,"Ben Green, Yiling Chen",,"Deployment and Integration-Human/Computer Handoff/General, Problem Identification",FAccT,2019,https://dl.acm.org/doi/10.1145/3287560.3287563,
260,On the Fairness of Machine-Assisted Human Decisions,"Bryce McLaughlin, Jann Spiess,  Talia Gillis",,"Deployment and Integration-Human/Computer Handoff, Problem Identification",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533152,
261,Human-algorithm collaboration: Achieving complementarity and avoiding unfairness,"Kate Donahue, Alexra Chouldechova,  Krishnaram Kenthapadi",,"Deployment and Integration-Human/Computer Handoff, Problem Identification",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533221,
262,"Race, Gender and Beauty: The Effect of Information Provision on Online Hiring Biases","Weiwen Leung, Zheng Zhang, Daviti Jibuti, Jinhao Zhao, Maximilian Klein, Casey Pierce, Lionel Robert,  Haiyi Zhu",,"Deployment and Integration-Human/Computer Handoff, Problem Identification",CHI,2020,https://dl.acm.org/doi/10.1145/3313831.3376874,
263,Not Just a Preference: Reducing Biased Decision-making on Dating Websites,"Zilin Ma, Krzysztof Z. Gajos",,"Deployment and Integration-Human/Computer Handoff, Problem Identification",CHI,2022,https://dl.acm.org/doi/10.1145/3491102.3517587,
264,"Took a Pic and Got Declined, Vexed and Perplexed: Facial Recognition in Algorithmic Management",Elizabeth Anne Watkins,,"Deployment and Integration-Human/Computer Handoff, Problem Identification",CSCW,2020,https://dl.acm.org/doi/10.1145/3406865.3418383,
265,How Child Welfare Workers Reduce Racial Disparities in Algorithmic Decisions,"Hao-Fei Cheng, Logan Stapleton, Anna Kawakami, Venkatesh Sivaraman, Yanghuidi Cheng, Diana Qing, Adam Perer, Kenneth Holstein, Zhiwei Steven Wu,  Haiyi Zhu",,"Deployment and Integration-Human/Computer Handoff, Measurement",CHI,2022,https://dl.acm.org/doi/10.1145/3491102.3501831,
266,Data-Centric Explanations: Explaining Training Data of Machine Learning Systems to Promote Transparency,"Ariful Islam Anik, Andrea Bunt",,"Deployment and Integration-Human/Computer Handoff, Mitigation",CHI,2021,https://dl.acm.org/doi/10.1145/3411764.3445736,
267,Fairness-Aware Programming,"Aws Albarghouthi, Samuel Vinitsky",,"Deployment and Integration-Maintenance Oversight, Measurement",FAccT,2019,https://dl.acm.org/doi/10.1145/3287560.3287588,
268,"""The human body is a black box"": supporting clinical decision-making with deep learning","Mark Sendak, Madeleine Clare Elish, Michael Gao, Joseph Futoma, William Ratliff, Marshall Nichols, Armo Bedoya, Suresh Balu,  Cara O’Brien",,"Deployment and Integration-General, Problem Identification (Case Study)",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372827,
269,The impact of overbooking on a pre-trial risk assessment tool,"Kristian Lum, Chesa Boudin,  Megan Price",,"Deployment and Integration-General, Problem Identification (Case Study)",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372846,
270,Long-term Dynamics of Fairness Intervention in Connection Recommender Systems,"Nil-Jana Akpinar, Cyrus DiCiccio, Preetam Ny,  Kinjal Basu",,"Deployment and Integration-General, Problem Identification",AIES,2022,https://dl.acm.org/doi/10.1145/3514094.3534173,
271,Designing Fair AI in Human Resource Management: Understanding Tensions Surrounding Algorithmic Evaluation and Envisioning Stakeholder-Centered Solutions,"Hyanghee Park, Daehwan Ahn, Kartik Hosanagar,  Joonhwan Lee",,"Deployment and Integration-General, Problem Identification",CHI,2022,https://dl.acm.org/doi/10.1145/3491102.3517672,
272,Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI,"Michael A Madaio, Luke Stark, Jennifer Wortman Vaughan,  Hanna Wallach",,"Deployment and Integration-General, Problem Identification",CHI,2020,https://dl.acm.org/doi/10.1145/3313831.3376445,
273,The Principles and Limits of Algorithm-in-the-Loop Decision Making,"Ben Green, Yiling Chen",,"Deployment and Integration-General, Problem Identification",CSCW,2019,https://dl.acm.org/doi/10.1145/3359152,
274,How Child Welfare Workers Reduce Racial Disparities in Algorithmic Decisions,"Hao-Fei Cheng, Logan Stapleton, Anna Kawakami, Venkatesh Sivaraman, Yanghuidi Cheng, Diana Qing, Adam Perer, Kenneth Holstein, Zhiwei Steven Wu,  Haiyi Zhu",,"Deployment and Integration-General, Problem Identification",CHI,2022,https://dl.acm.org/doi/10.1145/3491102.3501831,
275,A Case for Humans-in-the-Loop: Decisions in the Presence of Erroneous Algorithmic Scores,"Maria De-Arteaga, Riccardo Fogliato,  Alexra Chouldechova",,"Deployment and Integration-General, Problem Identification",CHI,2020,https://dl.acm.org/doi/10.1145/3313831.3376638,
276,FairCanary: Rapid Continuous Explainable Fairness,"Avijit Ghosh, Aalok Shanbhag,  Christo Wilson",,"Deployment and Integration-General, Measurement",AIES,2022,https://dl.acm.org/doi/10.1145/3514094.3534157,
277,Fairness Guarantees under Demographic Shift,"Stephen Giguere, Blossom Metevier, Yuriy Brun, Philip S. Thomas, Scott Niekum,  Bruno Castro da Silva",,"Deployment and Integration-General, Measurement",ICLR,2022,https://openreview.net/forum?id=wbPObLm6ueA,
278,Fairness warnings and fair-MAML: learning fairly with minimal data,"Dylan Slack, Sorelle A. Friedler,  Emile Givental",,"Deployment and Integration-General, Measurement",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3372839,
279,Models for understanding and quantifying feedback in societal systems,"Lydia Reader, Pegah Nokhiz, Cathleen Power, Neal Patwari, Suresh Venkatasubramanian,  Sorelle Friedler",,"Deployment and Integration-General, Measurement",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533230,
280,Towards Non-Parametric Drift Detection via Dynamic Adapting Window Independence Drift Detection (DAWIDD),"Fabian Hinder, André Artelt,  Barbara Hammer",,"Deployment and Integration-General, Measurement",ICML,2020,https://proceedings.mlr.press/v119/hinder20a.html,
281,Ensuring Fairness under Prior Probability Shifts,"Arpita Biswas, Suvam Mukherjee",,"Deployment and Integration-General, Measurement",AIES,2021,https://dl.acm.org/doi/abs/10.1145/3461702.3462596,
282,Bidding strategies with gender nondiscrimination constraints for online ad auctions,"Milad Nasr, Michael Carl Tschantz",,"Deployment and Integration-General, Mitigation",FAccT,2020,https://dl.acm.org/doi/10.1145/3351095.3375783,
283,ABCinML: Anticipatory Bias Correction in Machine Learning Applications,"Abdulaziz A. Almuzaini, Chidansh A. Bhatt, David M. Pennock,  Vivek K. Singh",,"Deployment and Integration-General, Mitigation",FAccT,2022,https://dl.acm.org/doi/10.1145/3531146.3533211,
284,Active Fairness in Algorithmic Decision Making,"Alejro Noriega-Campero, Michiel A. Bakker, Bernardo Garcia-Bulle,  Alex ’Sy’ Pentl.",,"Deployment and Integration-General, Mitigation",AIES,2019,https://dl.acm.org/doi/10.1145/3306618.3314277,
285,A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle,"Harini Suresh, John Guttag",,"Deployment and Integration-General, Mitigation",EAAMO,2021,https://dl.acm.org/doi/fullHtml/10.1145/3465416.3483305,
286,Predict responsibly: improving fairness and accuracy by learning to defer,"David Madras, Toni Pitassi,  Richard Zemel",,"Deployment and Integration-General, Mitigation",NeurIPS,2018,https://dl.acm.org/doi/10.5555/3327345.3327513,
